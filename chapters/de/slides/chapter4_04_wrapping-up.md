---
type: slides
---

# Abschluss

Notes: Gl√ºckwunsch ‚Äì du hast das Ende des Kurses erreicht!

---

# Deine neuen spaCy-Skills

- Extrahiere **linguistische Eigenschaften**: Wortarten, Relationen, Entit√§ten
- Arbeite mit vortrainierten **statistischen Modellen**
- Finde W√∂rter und Ausdr√ºcke mit `Matcher`- und `PhraseMatcher`-**Regeln**
- Best Practices im Umgang mit den **Datenstrukturen** `Doc`, `Token` `Span`,
  `Vocab`, `Lexeme`
- Finde **semantische √Ñhnlichkeiten** mit **Wortvektoren**
- Schreibe benutzerdefinierte **Pipeline-Komponenten** mit **erweiterten
  Attributen**
- **Skaliere** deine spaCy-Pipelines und mache sie schneller
- Erstelle **Trainingsdaten** f√ºr spaCys statistische Modelle
- **Trainiere und aktualisiere** spaCys Modelle mit neuen Daten

Notes: Hier ist eine √úbersicht √ºber alles, was du bisher gelernt hast:

Im ersten Kapitel hast du gelernt, linguistische Eigenschaften wie Wortarten,
Dependenzrelationen und Entit√§ten zu extrahieren, und mit vortrainierten
statistischen Modellen umzugehen.

Du hast au√üerdem gelernt, leistungsstarke Patterns f√ºr spaCys `Matcher` und
`PhraseMatcher` zu erstellen, um damit W√∂rter und Ausdr√ºcke zu finden.

Im zweiten Kapitel drehte sich alles um Informationsextraktion, und du hast
gelernt, mit den Datenstrukturen `Doc`, `Token` und `Span`, sowie mit dem
`Vocab` und lexikalischen Eintr√§gen zu arbeiten.

Du hast au√üerdem mit spaCy semantische √Ñhnlichkeiten anhand von Wortvektoren
vorhergesagt.

Das dritte Kapitel bescherte dir tiefere Einblicke in spaCys Pipeline und du
hast gelernt, deine eigenen benutzerdefinierten Pipeline-Komponenten zu
erstellen, die das Doc bearbeiten.

Du hast au√üerdem mithilfe von Erweiterungen eigene Attribute zu Docs, Tokens und
Spans hinzugef√ºgt, und gelernt, wie du Texte als Streams verarbeiten und deine
Pipelines schneller machen kannst.

Im vierten Kapitel hast du schlie√ülich gelernt, wie du spaCys statistische
Modelle, insbesondere den Named Entity Recognizer, trainieren und aktualisieren
kannst.

Du hast au√üerdem ein paar Tricks gelernt, die dir dabei helfen k√∂nnen,
Trainingsdaten zu erstellen und deine Labelsysteme zu gestalten, um die besten
Ergebnisse zu erzielen.

---

# Weiterf√ºhrendes mit spaCy (1)

- Andere Pipeline-Komponenten
  [trainieren und aktualisieren](https://spacy.io/usage/training)
  - Part-of-speech Tagger
  - Dependency Parser
  - Text Classifier

Notes: Nat√ºrlich gibt es noch viel mehr Dinge, die du mit spaCy machen kannst
und die wir in diesem Kurs nicht mehr behandeln konnten.

W√§hrend wir uns haupts√§chlich mit dem Trainieren des Entity Recognizers
besch√§ftigt haben, kannst du ebenfalls andere statistische Pipeline-Komponenten
wie den Part-of-speech Tagger oder den Dependency Parser aktualisieren.

Eine weitere n√ºtzliche Pipeline-Komponente ist der Text Classifier, der lernen
kann, Labels vorherzusagen, die auf den gesamten Text zutreffen. Er ist nicht
Teil der vortrainierten Modelle, aber du kannst ihn zu einem vorhandenen Modell
hinzuf√ºgen und mit deinen eigenen Daten trainieren.

---

# Weiterf√ºhrendes mit spaCy (2)

- [Tokenisierung anpassen](https://spacy.io/usage/linguistic-features#tokenization)
  - Regeln und Ausnahmen hinzuf√ºgen, um Text anders aufzuteilen
- [Unterst√ºtzung f√ºr weitere Sprachen hinzuf√ºgen oder verbessern](https://spacy.io/usage/adding-languages)
  - Derzeit 55+ Sprachen
  - Viel Potenzial f√ºr Verbesserungen und neue Sprachen
  - Erm√∂glicht das Trainieren von Modellen f√ºr weitere Sprachen

Notes: In diesem Kurs haben wir die standardm√§√üige Tokenisierung einfach so
akzeptiert, wie sie ist. Aber das musst du nicht.

spaCy erm√∂glicht es, die Regeln anzupassen, die verwendet werden, um zu
entscheiden, wie ein Text in Tokens aufgeteilt werden soll.

Du kannst au√üerdem die Unterst√ºtzung f√ºr verschiedene Sprachen verbessern oder
neue Sprachen hinzuf√ºgen.

spaCy unterst√ºtzt zwar bereits Tokenisierung f√ºr viele verschiedene Sprachen,
aber es gibt immer Verbesserungspotenzial.

Tokenisierung f√ºr eine neue Sprache ist der erste Schritt auf dem Weg zum
Trainieren eines neuen statistischen Modells.

---

# Mehr Infos und Dokumentation auf der Website!

<img src="/website.png" alt="Laptop, der die spacy.io-Website zeigt" width="50%" />

üëâ [spacy.io](https://spacy.io)

Notes: Wenn du mehr Beispiele, Tutorials und die tiefgreifende API-Dokumentation
sehen willst, schau dir die spaCy-Website an.

---

# Danke und bis bald! üëã

Notes: Vielen Dank, dass du diesen Kurs absolviert hast! Ich hoffe, du hattest
Spa√ü, und ich freue mich drauf, zu h√∂ren, was du cooles mit spaCy entwickelst.
